показал демо подсчёта правок
добавил полей, которых не хватало
продумал обратную связь про начало-конец правки
сделал выгрузку по organization id
подготовился к design review
  попробую договориться на сегодня ~ 17 00
  - пример выгрузки прямо из бд для дизайн ревью?


Викли
-----
В задаче про подсчёт правок после MT и фрилов, сделал чтение из базы всех
нужных коллекций, дальше буду писать код, считающий правки. Где-то завтра будет
готово.

Если есть хостить блокнот, мне нужно будет попросить devops завести нам не-GPU
тачку под VPN smartcat.

В прошлый викли не связал 2+2, скажу сейчас. Мы хотим различать в данных типы
TM матча fuzzy/100%, но в базе не хранится привязка, какой именно TM был
применён к сегменту. Инфу не трудно прикопать.

Дата правки не входит ключ

Дейли
-----
 Продумывал, в каком порядке обходить сегменты
  - сейчас смотрим на даты ревизии, т.к. на 1 сегмент приходится много ревизий
    с разными датами, проход с окном по дате ревизий зацепит сегмент много раз
  - хочется минимизировать повторный анализ того же сегмента
    - казалось бы, стоит дождаться окончания правок, какого то финального статуса
      сегмента, этапа воркфлоу, документа или проекта, и тогда смотреть на сегмент.
    - но мы не хотим исключать из статистики правки, которые так и не были завершены
      или оплачен и т.д.
  - разумным компромиссом выглядит смотреть на дату последней ревизии последнего таргета.
    повторный просмотр сегмента не исключён, но минимизирован при разборе истории глубоко
    в прошлом.
  - защиту от двойного учёта правок обеспечивает только ключ в коллекции счётчика правок.

Конфликт между учётом даты правки и аддитивностью счётчиков
- правки в пределах 1 сегмента не аддитивны
- чтобы избежать граблей при анализе данных, следуент придерживаться аддитивности

цена сохранения аддитивности
- дата правки не может входить в ключ
  - напр вчера была правка за дату X, сегодня её больше нет, правка данного сегмента
    теперь учитывается в дате X + 1
  - соотвественно, импорт данных в BI не может опираться на дату правки
    - документы в коллекции счётчика правок должны будут содержать дату
      обновления, на неё и будет ориентироваться BI

Дальше
~~~~~~

- Прокликать сценарии suggest-а
- Поискать в коде метрики, которых нам не хватает, запланировать добавление
  недостающих

Предложение
~~~~~~~~~~~
Свести историю по интересующим нас метрикам (факт приглашения, соблюдение срока
и тп., вместе со scoring-ом в единый набор данных, чтобы можно было оценивать,
на что и как сильно повлияет какое-либо изменение в scoring-е.

---
[ ] После завершения A/B дать отмашку devops убрать URL new из

Ревью Torch Serve
-----------------

- init.py, почему нет функции main
  - переименовать, чтобы не было впечатления, что кто-то забыл __{}__
    можно в initialize.py или cache_model.py
  - что такое `'./'`, это Current Working Directory, директория скрипта?
    сделать так, чтобы не нужно было гадать.
      - скачивать модель прямо в директорию с кодом выглядит неряшливо
  - скрипт инициаcd лзиции вряд ли уместен в директории src, это место для кода
    сервиса

- внешяя зависимость сервиса от скрипта инициализации
  - не задокументировано
  - не обеспечено понятное сообщение об ошибке, если make init_vx не был
    выполнен
  - локальная директория с моделью безымянная, читая код невозможно понять,
    какую мы вообще модель используем

Идея ассоциативной памяти
-------------------------

Представим, что гипотеза порядка входных данных подтвердится. Как это
эксплуатировать систематически?

Считаем, что обучение длится > 1 эпохи
Во время обучения генерируются промежуточные эмбеддинги
Складываем их в граф для векторной базы, напр HNSW
В каждую след. эпоху проходим по входным данным в порядке обхода графа

Дейли
-----
Завёл MR на интеграцию TSS и VIS
  Нельзя вливать до задачи Андрея про базовую модель и до задачи девопсов про
  одновременный деплой 2-го TorchServe

Спросить у Андрея, что будет если влить в девелоп MR с базовой моделью
TorchServe

Предложить задеплоить отдельно новую модель с даунтаймом

  - Чтобы решать проблему по частям, проблемы новой модели V3 будут решены
    отдельно от VIS
  - Будет меньше непредсказуемых проблем, в случае необходимости откатить
    отдельно V3
  - Даунтайм произойдёт на деплое более лёгкой задачи, что безопаснее, чем
    даунтайм на деплое толстой задачи


Набросы на исследования в след квартале
---------------------------------------

- Цель поразить в первую очередь потребителей smartcat из области перевода
  обучающих материалов Learn and Development

- Извлечение субтитров.
  На это дело выделили работу нескольких команд в след. квартале, ML команда
  должна будет подготовить сервис c API

- Извлечение текста из видео. На эту тему Игорь кидал видос с успешно работающим
  извлечением текста из обучающего видео про то какие кнопки жмакать в некотором
  приложении

- Классифицировать контент как обучающий, чтобы приложение или сотрудники
  smartcat могли таргетировать таких пользователей

- Переформулирование фразы, paraphrase, чтобы уместить текст разметку, либо
  звук в отведённый временной интервал

---

Достижения
----------

- Поднял для команды инфраструктуру Python разработки, включая сервера jupyter.
  - Благодаря этому удалось избежать ситуации, когда исследования команды
    разбросаны по личным аккаунтам разработчиков на сторонних сервисах типа
    google-colab.
  - Также это позволило добиться нетипичной для команд datasience ситуации,
    когда изменения в блокнотах легко ревьювить в gitlab, что дало команде
    доступ к пользе, которую приносит процесс code-review.
  - Задокументировал соглашения команды по оформлению исследований
  - Нашёл / внедрил технические решения, которые позволяют смягчить трудности,
    связанные с плохой масштабируемостью блокнтов jupyter
    - Переиспользование jupyter kernel между разными блокнотами
    - Общая память
    - датафреймы Polars вместо pandas
- Предложил команде использовать собственный аккаунт amazon, учитывая бутылочное
  горлышко devops. Помог коллегам совершить первые шаги с AWS
- Сделал матричный отчёт по задачам за квартал в Youtrack, чтобы минимизировать
  ручные действия и избежать двойной бюрократии при повседневной работе с
  задачами.
- APE
  - подобрал перспективного кандидата на техническое решение OpenNMT-APE
  - несмотря на первоначально неблагоприятные результаты измерений, проявил
    изобретательность и добился условий, в которых технология показала
    значительное улучшение MT
  - работа над APE была приостановлена в пользу TSS
- TSS
  - Значительно снизил время запуска сервиса, потребление памяти, размер базы.
  - На прядок ускорил прогон тестов, что позволило нам комфортно дорабатывать
    TSS, и команде инфраструктуры без проблем приносить в TSS свои разработки.
  - Наладил полноценный прогон тестов в CI, несмотря на devops и
    инфраструктурные проблемы, причём пришлось проделать работу не только со
    стороны TSS, но и порешать проблемы вместо инфры и девопс, потому что они
    за месяцы так и не осилили разобраться, а потом Мэтью вообще уволился.
  - Повысил подробность логирования, чтобы при диагностике мы могли по логам
    понимать общую картину, была ли какая-то выдача у TSS, и какие максимальные
    оценки присвоены найденным фрилам.
  - Разобрался в общих принципах ранжирования подобранных фрилов в smartcat,
    как в эту схему встроена выдача TSS.
  - Разобрался в методике оценки сходства текстов TSS, идентифицировал причины
    понижающие количество и качество выдачи.
  - Спроектировал механизм интроспекции для алгоритма оценки сходства текстов,
    который позволил легко и быстро рассматривать детализацию, почему
    сформирована именно такая выдача, какие конкретно сегменты в наибольшей
    степени повлияли на результат, что исключило необходимость глазами искать
    сходство либо его отсутствие в больших кусках текста.
- Микспанель
  - Сделал многие дашборды для TSS
  - Особенно стоить выделить дашборд Ретеншена, % повторных приглашений в
    зависимости от источника 1-го приглашения. Несмотря на мутную и во многом
    бесполезную документацию Микспанели, удалось найти идиоматичный (родной)
    способ решить эту задачу, что позволило избежать доп. правок событий на
    стороне smartcat
- Индексация векторов
  - Когда команда искала решение, сфокусировал внимание коллег на эффективности,
    с которой потенциальные решения используют аппаратные ресурсы
  - Когда исследовали технологию granne,
    - смог получить желаемый результат, несмотря на скудную документацию и
      незнакомый язык Rust
    - добился создания индекса out of RAM, хотя из коробки этого было сделать
      нельзя, т.к. разобрался во внутреннем устройстве и формате файлов granne,
      что в итоге открыло дверь для RAM-независимого масштабирования размера
      индекса
- VIS
  - Спроектировал сервис для индексации векторов на основе granne
  - Декомпозировал задачи разработки с аккуратным учётом зависимостей, что
    позволило построить диаграмму Гантта в Youtrack, что позволило в
    процессе работы оценивать сроки и прогресс с учётом возможностей
    параллельной разработки.
  - написал с нуля первый в компании сервис на Python с полноценной
    инфраструктурой для разработки - виртуальное окружение/ управление пакетами,
    линтинг, пирамида тестов
  - поставил team-devops внятную задачу на развёртывание сервиса

---
[x] В чём была причина плохих запросов из smartcat в TSS уже ясно?
    Появилась ли диагностика поля, из за которого BadRequest
    Так и не сделали норм. диагностику

[x] Выровнять эпики в ютреке с планами на Q4

[v] Убедиться, что можно легко вытащить из ютрек проделанную работу за квартал
    и классифицировать её по целям квартала, либо как "песок", который нельзя
    привязать к продвижению по одной из целей квартала - починка багов,
    тушение пожаров, и проч.

Лёня
---
Если записывать "можно / нельзя" торговать, то через год бэктестированием
можно подобрать оптимальные параметры тактики. Использовать кросс-валидацию
для контроля предсказательной силы.

---
[ ] Пройти все уроки fast.ai
[ ] Пройти туториал на huggingface
ikIu5ElG
mdb-london.sc-eu.local
